{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/zoeuthbwp3OK1amfPoND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekRP2002/ML-AI-Notes-and-Self-Practice/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://regex101.com/"
      ],
      "metadata": {
        "id": "6sR116f3h_85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0D50Lb0fayz"
      },
      "outputs": [],
      "source": [
        " import re  # allows to do pattern matching\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "Elon musk's phone number is 9991116666, call him if you have any questions on dodgecoin. Tesla's revenue is 40 billion\n",
        "Tesla's CFO number (999)-333-7777\n",
        "'''\n",
        "pattern = '\\(\\d{3}\\)-\\d{3}-\\d{4}|\\d{10}'\n",
        "\n",
        "matches = re.findall(pattern, text)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiceXNAchs_o",
        "outputId": "4593f3b0-fa4b-4677-d95b-92c21ea88f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9991116666', '(999)-333-7777']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat1='codebasics: Hello, I am having an issue with my order # 412889912'"
      ],
      "metadata": {
        "id": "jFlO7dCdh2XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = 'order[^\\d]*(\\d*)'\n",
        "matches = re.findall(pattern , chat1)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xG0973IjcSb",
        "outputId": "e146b5b7-c14a-40e7-b6ff-4da20dc3f5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['412889912']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat2='codebasics: I have a problem with my order number 412889912'\n",
        "pattern = 'order[^\\d]*(\\d*)'\n",
        "matches = re.findall(pattern , chat2)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAwnkJ7sjvVQ",
        "outputId": "ab06e73f-bd87-40cc-8475-3db58fad9a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['412889912']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pattern_match(pattern, text):\n",
        "    matches = re.findall(pattern, text)\n",
        "    if matches:\n",
        "        return matches[0]\n",
        "\n",
        "get_pattern_match('order[^\\d]*(\\d*)' , chat1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nRIsrXeckE50",
        "outputId": "f2eb948a-2d11-48c4-9cf7-e2f687cd8714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'412889912'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "Born\tElon Reeve Musk\n",
        "June 28, 1971 (age 50)\n",
        "Pretoria, Transvaal, South Africa\n",
        "Citizenship\t\n",
        "South Africa (1971–present)\n",
        "Canada (1971–present)\n",
        "United States (2002–present)\n",
        "Education\tUniversity of Pennsylvania (BS, BA)\n",
        "Title\t\n",
        "Founder, CEO and Chief Engineer of SpaceX\n",
        "CEO and product architect of Tesla, Inc.\n",
        "Founder of The Boring Company and X.com (now part of PayPal)\n",
        "Co-founder of Neuralink, OpenAI, and Zip2\n",
        "Spouse(s)\t\n",
        "Justine Wilson\n",
        "​\n",
        "​(m. 2000; div. 2008)​\n",
        "Talulah Riley\n",
        "​\n",
        "​(m. 2010; div. 2012)​\n",
        "​\n",
        "​(m. 2013; div. 2016)\n",
        "'''"
      ],
      "metadata": {
        "id": "Kxfqg8wxk16p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_personal_information(text):\n",
        "    age = get_pattern_match('age (\\d+)', text)\n",
        "    full_name = get_pattern_match('Born(.*)\\n', text)\n",
        "    birth_date = get_pattern_match('Born.*\\n(.*)\\(age', text)\n",
        "    birth_place = get_pattern_match('\\(age.*\\n(.*)', text)\n",
        "    return {\n",
        "        'age': int(age),\n",
        "        'name': full_name.strip(),\n",
        "        'birth_date': birth_date.strip(),\n",
        "        'birth_place': birth_place.strip()\n",
        "    }"
      ],
      "metadata": {
        "id": "okWmaibskfEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_personal_information(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_7uhcc6k21z",
        "outputId": "0e0b0cae-d50e-4fdf-ba07-e73e866f29b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 50,\n",
              " 'birth_date': 'June 28, 1971',\n",
              " 'birth_place': 'Pretoria, Transvaal, South Africa',\n",
              " 'name': 'Elon Reeve Musk'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Born\tMukesh Dhirubhai Ambani\n",
        "19 April 1957 (age 64)\n",
        "Aden, Colony of Aden\n",
        "(present-day Yemen)[1][2]\n",
        "Nationality\tIndian\n",
        "Alma mater\t\n",
        "St. Xavier's College, Mumbai\n",
        "Institute of Chemical Technology (B.E.)\n",
        "Stanford University (drop-out)\n",
        "Occupation\tChairman and MD, Reliance Industries\n",
        "Spouse(s)\tNita Ambani ​(m. 1985)​[3]\n",
        "Children\t3\n",
        "Parent(s)\t\n",
        "Dhirubhai Ambani (father)\n",
        "Kokilaben Ambani (mother)\n",
        "Relatives\tAnil Ambani (brother)\n",
        "Tina Ambani (sister-in-law)\n",
        "'''"
      ],
      "metadata": {
        "id": "PRj66Mb1k-SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_personal_information(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytrUnpWdlFFj",
        "outputId": "5f49f580-c3dd-4ee1-ef70-52f1478b3fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 64,\n",
              " 'birth_date': '19 April 1957',\n",
              " 'birth_place': 'Aden, Colony of Aden',\n",
              " 'name': 'Mukesh Dhirubhai Ambani'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy vs NLTK (Difference btwn the two libraries)\n",
        "- Spacy is object oriented \n",
        "- NLTK is string processing based library.\n",
        "- Spacy provides most efficient NLP algorithm for a given task. Hence, for end result hoose spacy.\n",
        "- NLTK provides access to many algorithms , If you care about specific algo and custmizations go with NLTK\n",
        "- "
      ],
      "metadata": {
        "id": "mMLDkumhFDHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk"
      ],
      "metadata": {
        "id": "2gxrJNRulHpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp('Dr.Strange loves india. HUlk loves me .')\n",
        "\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ormDDCjNE5ck",
        "outputId": "bb451a65-be77-4b6c-a112-3bd534d53ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.Strange loves india.\n",
            "HUlk loves me .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blHecoIJGN9s",
        "outputId": "61364416-6007-4be9-eb25-12fdbe20d8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "india\n",
            ".\n",
            "HUlk\n",
            "loves\n",
            "me\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QaT2I7bHGY9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcSwYyfPGW5l",
        "outputId": "a38626b3-d59d-4f33-ce8d-1dcda7f9968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"Dr.Strange loves india. HUlk loves me .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnOxm13_HQQ9",
        "outputId": "17a54932-6fbe-416e-97e3-6a348c1a71a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.Strange loves india.', 'HUlk loves me .']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "word_tokenize(\"Dr.Strange loves india. HUlk loves me .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDLo54S6HaPq",
        "outputId": "7121f910-3808-49a0-8d4b-7bba4df449f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.Strange', 'loves', 'india', '.', 'HUlk', 'loves', 'me', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy Tokenization"
      ],
      "metadata": {
        "id": "7XVk4-qU0GGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "HZ9Lf4mTHsmo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxf8sw5T0UNE",
        "outputId": "cdcd037e-7df8-466b-b174-801a5337cffe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            "as\n",
            "it\n",
            "costs\n",
            "only\n",
            "2\n",
            "$\n",
            "per\n",
            "plate\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using index to grab tokens\n"
      ],
      "metadata": {
        "id": "08Mou7A01Hds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVM2ev3s1A9p",
        "outputId": "3fae294d-fc78-43b2-cfcb-7c06d9de6b84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = doc[1]\n",
        "token.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zP1KfmNw1Pq-",
        "outputId": "4e3d6f16-7ea7-4f03-caae-044d00d9f71a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Strange'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(token)"
      ],
      "metadata": {
        "id": "PBJSB1xR1U5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwvjShYo1XPP",
        "outputId": "ebe580bc-9f91-440f-d3c3-91516938d035"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLHWW-2V2pY1",
        "outputId": "a1906608-bd33-4a00-9d38-5d867bb8e558"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tony stark gave peter parker the spidey-x-suite worth $1000\")\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoUNBjYC2rRu",
        "outputId": "b9659667-0e07-4fe9-900f-698ae004daff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tony\n",
            "stark\n",
            "gave\n",
            "peter\n",
            "parker\n",
            "the\n",
            "spidey\n",
            "-\n",
            "x\n",
            "-\n",
            "suite\n",
            "worth\n",
            "$\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token atrributes \n"
      ],
      "metadata": {
        "id": "p5dcSeY75Hfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(token)  #gives list of attributes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LddGeG_P5Ji7",
        "outputId": "39e83ad1-4f6d-434a-d274-cb231a0fc23b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_dep',\n",
              " 'has_extension',\n",
              " 'has_head',\n",
              " 'has_morph',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'iob_strings',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_end',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'set_morph',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.is_alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdHSDz8R2-kU",
        "outputId": "64629f89-f529-447d-d62d-52944956b87c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.like_num\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zl8SrH14D9z",
        "outputId": "813aaf3e-acc5-46da-a3cf-e8b6c4dcc9a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha, \n",
        "          \"is_punct:\", token.is_punct, \n",
        "          \"like_num:\", token.like_num,\n",
        "          \"is_currency:\", token.is_currency,\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9IhU2SO4YeH",
        "outputId": "bd3fe5e2-1a8a-4a4a-e044-7bc6385f6260"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "stark ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "gave ==> index:  2 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "peter ==> index:  3 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "parker ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "the ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "spidey ==> index:  6 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "- ==> index:  7 is_alpha: False is_punct: True like_num: False is_currency: False\n",
            "x ==> index:  8 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "- ==> index:  9 is_alpha: False is_punct: True like_num: False is_currency: False\n",
            "suite ==> index:  10 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "worth ==> index:  11 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "$ ==> index:  12 is_alpha: False is_punct: False like_num: False is_currency: True\n",
            "1000 ==> index:  13 is_alpha: False is_punct: False like_num: True is_currency: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"hi\")\n",
        "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
        "for token in doc:\n",
        "    print(token, token.is_currency, token.like_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkftZ_QU4ecx",
        "outputId": "a9931728-7179-4525-8198-add8cc340289"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "भैया False False\n",
            "जी False False\n",
            "! False False\n",
            "5000 False True\n",
            "₹ True False\n",
            "उधार False False\n",
            "थे False False\n",
            "वो False False\n",
            "वापस False False\n",
            "देदो False False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customizing tokenizer"
      ],
      "metadata": {
        "id": "4qgHw33w5py7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmIde4IH4rN-",
        "outputId": "334bb18a-9b62-4063-ca22-17bb1cb1f8d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to split gimme into give me . our machine is lil dumb to get that "
      ],
      "metadata": {
        "id": "Ld3ZbsKA52Gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer.add_special_case(\"gimme\", [\n",
        "    {ORTH: \"gim\"},\n",
        "    {ORTH: \"me\"},\n",
        "])\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sES9lwih5r-l",
        "outputId": "4c42954b-d757-4836-d795-478e4a4ef7ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgQMFzru54tq",
        "outputId": "11bd3f0c-ea43-49fe-cd71-95f8449a944d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mumbai.\n",
            "Hulk loves chat of delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gvcivFr59eG",
        "outputId": "d35df2b4-3586-4f9a-ddee-0a25a9bfc716"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7fa204795a50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4LxQxUY9O5J",
        "outputId": "4536e89e-226a-4e09-9710-88345caf4387"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XARsFpWy9SBd",
        "outputId": "c84f34ba-6f9d-414a-cdf6-a4cdac78315d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fa205c1e0c0>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fa20472e8a0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fa2045afed0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fa2044ec5a0>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fa2044f9aa0>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fa2046e1050>)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_) #pos mtlb part of speech , lemma means lemmatization  , base word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xqVtXua9VAd",
        "outputId": "3aa8c30c-d7e7-4844-a0b5-21eac776b0ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |  proper noun  |  Captain\n",
            "america  |  proper noun  |  america\n",
            "ate  |  verb  |  eat\n",
            "100  |  numeral  |  100\n",
            "$  |  numeral  |  $\n",
            "of  |  adposition  |  of\n",
            "samosa  |  noun  |  samosa\n",
            ".  |  punctuation  |  .\n",
            "Then  |  adverb  |  then\n",
            "he  |  pronoun  |  he\n",
            "said  |  verb  |  say\n",
            "I  |  pronoun  |  I\n",
            "can  |  auxiliary  |  can\n",
            "do  |  verb  |  do\n",
            "this  |  pronoun  |  this\n",
            "all  |  determiner  |  all\n",
            "day  |  noun  |  day\n",
            ".  |  punctuation  |  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "3LcclrNy9giT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_, spacy.explain(ent.label_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DCKin949bGJ",
        "outputId": "d40dcab5-3e8e-42d5-d569-b5e4113d1c72"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc ORG Companies, agencies, institutions, etc.\n",
            "$45 billion MONEY Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "tUWi8Fae9law",
        "outputId": "29d0003b-122a-4104-dd19-eb8a4f334b69"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a component to a blank pipeline**"
      ],
      "metadata": {
        "id": "I86Csxdy_R6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"ner\", source=source_nlp)\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJJlgD0B9olY",
        "outputId": "af63f293-c66b-4e7a-f164-ff82a1c88861"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQifMBqm_U4e",
        "outputId": "43d985ca-5e36-42a0-a1a4-40834e639e8f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc ORG\n",
            "$45 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Elon flew to mars yesterday. He carried biryani masala with him\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-LGrNX3_fxn",
        "outputId": "6689aae0-bc38-4a6c-cf11-e7460a0eb416"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon  |  PROPN  |  proper noun\n",
            "flew  |  VERB  |  verb\n",
            "to  |  ADP  |  adposition\n",
            "mars  |  NOUN  |  noun\n",
            "yesterday  |  NOUN  |  noun\n",
            ".  |  PUNCT  |  punctuation\n",
            "He  |  PRON  |  pronoun\n",
            "carried  |  VERB  |  verb\n",
            "biryani  |  ADJ  |  adjective\n",
            "masala  |  NOUN  |  noun\n",
            "with  |  ADP  |  adposition\n",
            "him  |  PRON  |  pronoun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXjqv0NrAXRy",
        "outputId": "7495eeed-281c-4a3f-94d0-1d65d0fa9242"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow  |  INTJ  |  interjection\n",
            "!  |  PUNCT  |  punctuation\n",
            "Dr.  |  PROPN  |  proper noun\n",
            "Strange  |  PROPN  |  proper noun\n",
            "made  |  VERB  |  verb\n",
            "265  |  NUM  |  numeral\n",
            "million  |  NUM  |  numeral\n",
            "$  |  NUM  |  numeral\n",
            "on  |  ADP  |  adposition\n",
            "the  |  DET  |  determiner\n",
            "very  |  ADV  |  adverb\n",
            "first  |  ADJ  |  adjective\n",
            "day  |  NOUN  |  noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token,\" | \", token.pos_, \" | \", spacy.explain(token.pos_), \" | \", token.tag_ , spacy.explain(token.tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vz34AstAdmz",
        "outputId": "1b6fa0c8-7248-4c72-a738-d7b9ff777660"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow  |  INTJ  |  interjection  |  UH interjection\n",
            "!  |  PUNCT  |  punctuation  |  . punctuation mark, sentence closer\n",
            "Dr.  |  PROPN  |  proper noun  |  NNP noun, proper singular\n",
            "Strange  |  PROPN  |  proper noun  |  NNP noun, proper singular\n",
            "made  |  VERB  |  verb  |  VBD verb, past tense\n",
            "265  |  NUM  |  numeral  |  CD cardinal number\n",
            "million  |  NUM  |  numeral  |  CD cardinal number\n",
            "$  |  NUM  |  numeral  |  CD cardinal number\n",
            "on  |  ADP  |  adposition  |  IN conjunction, subordinating or preposition\n",
            "the  |  DET  |  determiner  |  DT determiner\n",
            "very  |  ADV  |  adverb  |  RB adverb\n",
            "first  |  ADJ  |  adjective  |  JJ adjective (English), other noun-modifier (Chinese)\n",
            "day  |  NOUN  |  noun  |  NN noun, singular or mass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vro39cx8AoZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}